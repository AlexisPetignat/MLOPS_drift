{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA_QTG8vFs8E"
   },
   "source": [
    "## Modèle en production\n",
    "\n",
    "Laurent Cetinsoy - Datadidacte\n",
    "\n",
    "Une des supposition centrale pour qu'un modèle de machine learning marche est que la distribution des données ne diffère pas de celle des données d'entrainement.\n",
    "\n",
    "On ne peut garantir la généralisation d'un modèle que si la distribution des données est similaire à celle de la distribution $ X_{prod} \\tilde{} \\,  P_{train}$\n",
    "\n",
    "Ainsi, si les données que le modèle voient en production n'ont pas la même distribution (ne ressemblent pas) aux données de train, alors le modèle aura peu de chance de faire de bonne prédictions.\n",
    "\n",
    "Il est donc important de surveille les données vues par le modèle en production.\n",
    "\n",
    "Pour cela on va mesurer ce qu'on appelle le Data drift : on va mesurer à quel point les données s'écartent des données de train.\n",
    "\n",
    "Et on pourra ainsi lever une alerte si c'est le cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEHFqy-yFs8K"
   },
   "source": [
    "## Utilisation Eurybia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Cr8DVyFs8N"
   },
   "source": [
    "\n",
    "En consultant la documentation de Eurybia (https://eurybia.readthedocs.io/en/latest/overview.html), expliquer le principe de fonctionnement de Euribya :\n",
    "\n",
    "- A quoi sert le modèle de classification ?\n",
    "- A-t-on besoin d’avoir les labels issus de la production pour pouvoir utiliser cette approche ?\n",
    "- Quel est le critère pour déterminer qu’il y a un data-drift ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2lpGujbFs8Q"
   },
   "source": [
    "**Eurybia met à disposition un modèle de classification binaire de données, spécifiant si la donnée fournie est une donnée d'entrainement ou une donnée réelle de production.**\n",
    "- Pour faire simple, on donne un item au modèle, et celui-ci tente de déterminer si l'item appartient à X_train ou X_test.\n",
    "- Les labels ne sont absolument pas nécessaires, puisqu'on ne s'intéresse pas à analyser la donnée de façon à obtenir le meilleur score possible, mais davantage à déterminer à quel point les données de train et de tests sont similaires. Ainsi, les labels nécessaires sont juste l'origine de l'item fourni.\n",
    "- L'unité de mesure utilisée par Eurybia est l'AUC (Area Under roc Curve).\n",
    "- Un AUC de 0.5 signifie que les données sont bien réparties autour de la courbe (au dessus et en dessous) et donc que les données de train et de production sont assez similaires.\n",
    "- En revanche, un AUC de 1 démontre un décalage entre les deux sets de données, et donc qu'un drift des données a lieu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAn3sAA7Fs8W"
   },
   "source": [
    "Installer eurybia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUCfIkyzFs8Z"
   },
   "outputs": [],
   "source": [
    "from eurybia import SmartDrift\n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('houses.csv')\n",
    "X = df[['size', 'nb_rooms', 'garden']]\n",
    "y = df['price']\n",
    "X_train, X_prod, y_train, y_prod = train_test_split(X, y, train_size=0.4)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "joblib.dump(model, \"regression.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qFJUvoFs8e"
   },
   "source": [
    "Utiliser eurybia pour monitorer la distribution des données. Dans un premier temps faire en sorte que les données de prod (df_current) soient de la même distribution que vos données d’entraînement. Pour cela vous pouvez split le dataset en deux et décider que l'un est X_train et l'autre est X_prod. Vérifier que Eurybia pense que le modèle ne drift pas. Attention à ne pas inclure le label (qui serait ici price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TjazQyrFs8i"
   },
   "outputs": [],
   "source": [
    "def evaluate(current, baseline) :\n",
    "\n",
    "    sd = SmartDrift(\n",
    "      df_current=current,\n",
    "      df_baseline=baseline,\n",
    "      dataset_names={\"df_current\": \"Houses.csv\", \"df_baseline\": \"Test Houses.csv\"} # Optional: Names for outputs\n",
    "      )\n",
    "    \n",
    "    sd.compile(\n",
    "      full_validation=True, # Optional: to save time, leave the default False value. If True, analyze consistency on modalities between columns.\n",
    "      )\n",
    "    \n",
    "    sd.generate_report(\n",
    "      output_file='output/report.html',\n",
    "      title_story=\"Eurybia starts\",\n",
    "      title_description=\"Not sus at all\", # Optional: add a subtitle to describe report\n",
    "      )\n",
    "    \n",
    "    print(\"Done!\")\n",
    "\n",
    "evaluate(X_prod, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpbUJGhzFs8m"
   },
   "source": [
    "Faire en sorte d'introduire un drift dans vos données. Par exemple (méthode assez bourine) ajouter +1 à la colonne nb_rooms. Relancer eurybia et vérifier que la performance du modèle est bonne et qu'il y a donc un datadrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pyIJbu5Fs8n"
   },
   "outputs": [],
   "source": [
    "scale = 10\n",
    "\n",
    "def addNoise(df, scale = 1.0) :\n",
    "    rng = np.random.default_rng(42)\n",
    "    noisy = df.copy()\n",
    "        \n",
    "    for col in noisy.select_dtypes(include=[np.number]).columns:\n",
    "        std = noisy[col].std()\n",
    "        noise = rng.normal(0, scale * std, size=len(noisy))\n",
    "        noisy[col] += noise\n",
    "    return noisy\n",
    "\n",
    "X_prod_noisy = addNoise(X_prod, scale)\n",
    "evaluate(X_prod_noisy, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jjw1gk8D2BeS"
   },
   "source": [
    "Faire en sorte de faire un drift plus subtile mais remarquable. Eurybia est-il détectable avec Eurybia ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpl-Zc4Y2BOj"
   },
   "outputs": [],
   "source": [
    "scale = 2\n",
    "\n",
    "def addNoise(df, scale = 1.0) :\n",
    "    rng = np.random.default_rng(42)\n",
    "    noisy = df.copy()\n",
    "        \n",
    "    for col in noisy.select_dtypes(include=[np.number]).columns:\n",
    "        std = noisy[col].std()\n",
    "        noise = rng.normal(0, scale * std, size=len(noisy))\n",
    "        noisy[col] += noise\n",
    "    return noisy\n",
    "\n",
    "X_prod_noisy = addNoise(X_prod, scale)\n",
    "evaluate(X_prod_noisy, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On remarque que l'AUC est à 0.64, ce qui est proche de 0.5, mais toutefois notable.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYnareE4Fs8o"
   },
   "source": [
    "## Alibaba detect\n",
    "\n",
    "Dans cette partie on va utiliser la librairie https://github.com/SeldonIO/alibi-detect pour faire la détection de problèmes\n",
    "Installer la librairie avec pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX5iAyTJFs8q"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJvFD2xrFs8r"
   },
   "source": [
    "Charger le jeu de donnée cifar10 avec keras et récupérer le train et le test puis,\n",
    "\n",
    "Normaliser les données de train en faisant un MinMaxScaling (diviser par 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X90oWx5AFs8v"
   },
   "outputs": [],
   "source": [
    "m = max(np.max(x_train), np.max(x_test))\n",
    "X_train_scaled = x_train / m\n",
    "X_test_scaled = x_test / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45x7yftfFs8w"
   },
   "source": [
    "Dans le sous package alibbi_detect.datasets importer les  fonction fetch_cifar10c et corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u6Pp8x9Fs80"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.datasets import fetch_cifar10c, corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH81nEs_Fs82"
   },
   "source": [
    "Afficher les types de corruption de données disponible avec la fonction corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH0zp3fbFs84"
   },
   "outputs": [],
   "source": [
    "print(corruption_types_cifar10c())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDTT-67yFs86"
   },
   "source": [
    "Avec la fonction fetch_cifar10c récupérer des exemples corrompus de donnée ressemblant à cifar 10 et les stocker dans des variable X_corrupted et y_corrupted.\n",
    "\n",
    "Vous choisirez 1 ou 2 corruptions parmis les suivantes : ['gaussian_noise', 'motion_blur', 'brightness', 'pixelate']\n",
    "\n",
    "Vous spécifirez les argument severity=5 et return_X_y=True\n",
    "attention le dataset peut être lourd si vous utilisez bcp de corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8SL8z_TFs8-"
   },
   "outputs": [],
   "source": [
    "X_corrupted, y_corrupted = fetch_cifar10c(['gaussian_noise', 'brightness'], severity=5, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilj7rn6aFs8_"
   },
   "source": [
    "Normaliser les images corrompues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tS0CR6e5Fs9B"
   },
   "outputs": [],
   "source": [
    "X_corrupted_scaled = X_corrupted / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_mTwk7yFs9B"
   },
   "source": [
    "Afficher plusieurs des images corrompues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHmjeAywFs9C"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(8, 6))\n",
    "axes = axes.ravel()\n",
    "for i in range(12):\n",
    "    axes[i].imshow(X_corrupted_scaled[i], cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")  # hide axes/ticks\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bev6XyQZFs9D"
   },
   "source": [
    "On va maintenant prendre un modèle entraîné sur cifar10 pour voir l'impact des performances sur le modèle.\n",
    "\n",
    "Avec la fonction  fetch_tf_model du module alibi_detect.utils.fetching, charger le modèle préentraîné resnet32 sur cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOkVyhy2Fs9G"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.utils.fetching import fetch_tf_model, fetch_detector\n",
    "dataset = 'cifar10'\n",
    "model_name = 'resnet32'\n",
    "model = fetch_tf_model(dataset, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSVWdspmFs9K"
   },
   "source": [
    "Calculer la performance du model sur le jeu de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyBxvmGaFs9M"
   },
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train, verbose=1)\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.4f}\")\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SG82jqxFs9N"
   },
   "source": [
    "Calculer la performance du modèle sur le jeu de donnée corrompu. Vous devriez observer qu'il chute significativement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWux1w8EFs9P"
   },
   "outputs": [],
   "source": [
    "corr_loss, corr_accuracy = model.evaluate(X_corrupted_scaled, y_corrupted, verbose=1)\n",
    "\n",
    "print(f\"Corrupted loss: {corr_loss:.4f}\")\n",
    "print(f\"Corrupted accuracy: {corr_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT9bns5tFs9Q"
   },
   "source": [
    "On va maintenant voir comment détecter les changement de distributions de données.\n",
    "\n",
    "Pour les données non tabulaire ou à haute dimension on procéde généralement en deux étapes :\n",
    "\n",
    "1. Faire une réduction de dimension\n",
    "2. Faire un test permettant de voir si les données projetées ont changé de distribution ou pas\n",
    "\n",
    "Il existe plusieurs manières de faire de la réduction de dimension. La plus classique est la PCA.\n",
    "\n",
    "Il est possible également d'utiliser des Auto-encoder\n",
    "\n",
    "Le code suivant permet de créer la première partie (l'encoder) d'un auto-encoder simple qui nous servira à réduire les dimension des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBJao1RXFs9R"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer, Reshape\n",
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# define encoder\n",
    "encoding_dim = 32\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(32, 32, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH4ZehyHFs9S"
   },
   "source": [
    "Le drift detector a besoin d'une donnée de référence afin d'effectuer la comparaison avec les données à monitorer.\n",
    "Créer une variable X_ref avec un échantillon aléatoire des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk6euJipFs9T"
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(np.arange(X_test_scaled.shape[0]), int(X_test_scaled.shape[0] * 0.3))\n",
    "X_ref = X_test_scaled[idx]\n",
    "y_ref = y_test[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZrtwSr4Fs9Z"
   },
   "source": [
    "A quoi sert le test statistique kolmogorov smirnoff ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XsIOHxBFs9d"
   },
   "source": [
    "**Le test de kolmogorov smirnoff sert à déterminer si un échantillon de données suit une loi de probabilité particulière, connue et dont la fonction de répartition est déterminée.**\n",
    "- Par exemple, étant donné un échantillon de données généré d'une façon inconnue, effectuer le test avec cet échantillon et une loi connue (par exemple la loi normale) permet d'affirmer ou réfuter le fait que l'échantillon inconnu soit issu de cette loi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXatEJZOFs9f"
   },
   "source": [
    "Instancier la classe KSDrift dans une variable nommée **detector**\n",
    "\n",
    "Il faut lui passer le dataset de reference, une p value (prendre 0.05) et une fonction permettant de faire le preprocessing. On a créé la fonction pour vous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epmDLfAfFs9i"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "preprocess_function = partial(preprocess_drift, model=encoder_net, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import KSDrift\n",
    "\n",
    "detector = KSDrift(X_ref, p_val=0.05, preprocess_fn=preprocess_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUSKpqulFs9k"
   },
   "source": [
    "A laide du Drift detector et la méthode predict faire des prediction sur les données de test et sur les données corrompue pour voir si il détecte un changement de distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfaYUukjFs9o"
   },
   "outputs": [],
   "source": [
    "r = detector.predict(X_test_scaled, drift_type='batch', return_p_val=True, return_distance=True)\n",
    "print(f\"Drift detected for test data: {True if r['data']['is_drift'] == 1 else False}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = detector.predict(X_corrupted_scaled, drift_type='batch', return_p_val=True, return_distance=True)\n",
    "print(f\"Drift detected for corrupted data: {True if r['data']['is_drift'] == 1 else False}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "drifty-venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
